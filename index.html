<!DOCTYPE HTML>

<html lang="en">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<head>
  <meta charset="utf-8">
  <title>ASR</title>
  <meta name="description" content="">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=PT+Sans+Narrow:regular,bold">
  <link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="css/styles.css">
</head>

<body id="home">
  <section class="main">
    <div id="Title" class="wrapper topSection">
      <div id="Header">
        <div class="logo">
          <h1>Automatic Speech Recognition</h1>
          <h2>for low-Resource Indic Languages</h2>
        </div>
      </div>
      <div class="Border">
        <a class="active" href="index.html">Home</a>
        <a href="languages.html">Languages</a>
        <a href="team_members.html">Team Members</a>
        <a href="contacts.html">Contacts</a>
      </div>
    </div>
  </section>

  <section class="content">
    <div class="container">
      <div id="contents">
        <h3>Objective</h3>
        <p>Building of ASR system for Extremely Low-Resource Indic Languages.
          We will focus on three highly under-resourced Indian languages
          that have no open speech datasets like Konkani, Maithili, and Santali.</p>
        <h3>Details</h3>
        <h4>Automatic Speech Recognition (ASR):</h4>
        <ul>
          <li>Has made impressive strides in recent years and is seeing widespread adoption in various applications.
          </li>
          <li>Existing ASR systems require large amounts of labeled speech in order to perform competitively, creating a
            dichotomy between high-resource languages (with access to large labeled speech corpora) and low-resource or
            under-resourced languages (with minimal access to labeled speech data).</li>
          <li>Existing ASR systems require large amounts of labeled speech in order to perform competitively, creating a
            dichotomy between high-resource languages (with access to large labeled speech corpora) and low-resource or
            under-resourced languages (with minimal access to labeled speech data).</li>
          <li>A recent study on open voice data in Indian languages reveals that the top ten Indian languages based on
            the
            amount of labeled speech averages less than 250 hours, and the remaining Indian languages have little to nil
            amounts of accompanying labeled speech.</li>
          <li>These languages have native speakers hailing from multiple Indian states, including Goa, Bihar, Jharkhand,
            Karnataka, Maharashtra, Assam, Mizoram, Odisha, Tripura and West Bengal.</li>
        </ul>
        <h4>Data Characteristics:</h4>
        <ul>
          <li>Unlike almost all the Indian language speech datasets that focus on read speech, we will aim to collect
            speech in an interview style from native speakers resulting in more spontaneous speech for all three
            languages.</li>
          <li>While prompt-based data collection is commonly employed to collect read speech, this could lead to
            challenges where prompts created by speakers of a specific dialect are unfamiliar to speakers of a different
            dialect of the same language.</li>
          <li>Interview-style speech data collection allows us to bypass such concerns and also potentially collect
            speech in many dialects. </li>
          <li>Interview-style speech data collection allows us to bypass such concerns and also potentially collect
            speech in many dialects. </li>
          <li>For data collection, we will also investigate crowdsourcing for a speech from native speakers via an
            Android app called CLAP, which was developed by one of the PIs as part of an IMPRINT-2 grant. </li>
        </ul>
        <h4>Aim:</h4>
        <ul>
          <li>To collect 300 hours of transcribed conversational speech in each language. (As a frame of reference, the
            most popular conversational speech dataset for English Switchboard consists of roughly 200 hours of speech.)
          </li>
          <li>Will focus on the agricultural domain for all three languages.</li>
          <li>Evaluate our target languages using existing pretrained multilingual models (e.g. XLSR)</li>
          <li>Develop</li>
          <ul>
            <li>Adaptation techniques to finetune the pretrained models with labeled data in the target languages.</li>
            <li>Self-supervision techniques that help the models perform better on conversational-style speech in our
              target languages.</li>
            <li>Transfer learning approaches that help utilize conversational speech in one target language for the
              other target languages.</li>
          </ul>
          <li>Curated datasets consisting of around 300 hours of conversational speech in Konkani, Maithili and Santali
          </li>
          <li>Web APIs for domain-specific ASR in all three languages serve as initial prototypes.</li>
          <li>Android apps catering to each domain-specific ASR will be further refined with user feedback.</li>
        </ul>
      </div>

      <section class="features spacing">
        <div class="container">
          <h2>ASR Demo</h2>
          <div class="row">
            <div class="col-6 col-md-4">
              <button onclick="ln()">Maithili</button>
              <li>Maithili-Indo-Aryan languages</li>
              <li>Maithili has 13.5 million native speakers</li>
            </div>
            <div class="col-6 col-md-4">
              <button onclick="ln()">Konkani</button>
              <li>Konkani-Indo-Aryan languages</li>
              <li>Konkani has around 2.2 million native speakers</li>
            </div>
            <div class="col-6 col-md-4">
              <button onclick="ln()">Santhali</button>
              <li>Santali-Austroasiatic language</li>
              <li>Santali has 7.3 million native speakers </li>
            </div>
          </div>
      </section>

      <span class="footer">
        <p><a href="https://iisc.ac.in/"><img id="iisc" src="images/IISC.png"></a></p>
        <p><a href="hhttps://www.iitb.ac.in/"></a><img id="iitb" src="images/IITB.png"></a></p>
          <p><a href="https://spire.ee.iisc.ac.in/spire/"><img id="spire" src="images/SPIRE.png"></a></p>
      </span>

      <!--Scripts-->
      <script type="text/javascript" src="js/jquery-1.9.1.min.js"></script>
      <script type="text/javascript" src="js/global.js"></script>
      <script type="text/javascript" src="js/script.js"></script>

</body>

</html>